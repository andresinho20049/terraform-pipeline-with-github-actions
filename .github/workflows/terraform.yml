name: "Terraform Workflow"

on:
  workflow_call:
    inputs:
      environment:
        type: string
        required: true
      aws-region:
        type: string
        required: true
    secrets:
      TF_AWS_ROLE_ARN:
        required: true
      TF_AWS_STATEFILE_S3_BUCKET:
        required: true
      TF_AWS_LOCK_DYNAMODB_TABLE:
        required: true

jobs:
  terraform:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.8.3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.TF_AWS_ROLE_ARN }}
          role-session-name: github-actions-pipeline-to-aws
          aws-region: ${{ inputs.aws-region }}

      - name: Read destroy configuration
        id: read-destroy-config
        run: |
          DESTROY="$(jq -r '.${{ inputs.environment }}' ./infra/destroy_config.json)"
          echo "destroy=$(echo $DESTROY)" >> $GITHUB_OUTPUT

      - name: Terraform Init
        run: |
          cd infra && terraform init \
            -backend-config="bucket=${{ secrets.TF_AWS_STATEFILE_S3_BUCKET }}" \
            -backend-config="key=${{ github.event.repository.name }}" \
            -backend-config="region=${{ inputs.aws-region }}" \
            -backend-config="dynamodb_table=${{ secrets.TF_AWS_LOCK_DYNAMODB_TABLE }}"

      - name: Terraform Validate
        run: terraform validate

      - name: Terraform Plan
        if: steps.read-destroy-config.outputs.destroy != 'true'
        id: terraform-plan
        run: |
          # Navega para o diretÃ³rio infra antes de executar os comandos terraform
          cd infra
          terraform workspace select ${{ inputs.environment }} || terraform workspace new ${{ inputs.environment }}
          terraform plan \
            -var-file="./envs/${{ inputs.environment }}/terraform.tfvars" \
            -var="account_username=${{ github.actor }}" \
            -var="region=${{ inputs.aws-region }}" \
            -var="environment=${{ inputs.environment }}" \
            -out="${{ inputs.environment }}.plan"

      - name: Terraform Apply
        if: steps.read-destroy-config.outputs.destroy != 'true'
        id: terraform-apply
        run: |
          cd infra
          terraform workspace select ${{ inputs.environment }} || terraform workspace new ${{ inputs.environment }}
          terraform apply "${{ inputs.environment }}.plan"

      - name: Upload Static Files to S3
        if: steps.read-destroy-config.outputs.destroy != 'true' && steps.terraform-apply.conclusion == 'success'
        run: |
          AWS_S3_BUCKET_NAME=$(terraform -chdir=infra output -raw s3_static_site_bucket_name)
          echo "Uploading files from src/ to s3://${AWS_S3_BUCKET_NAME}/"
          aws s3 sync src/ s3://${AWS_S3_BUCKET_NAME}/ --delete

      # Only run the following steps if the destroy flag is set to true
      - name: Get S3 Bucket Name for Destroy
        id: get-s3-bucket-name-destroy
        if: steps.read-destroy-config.outputs.destroy == 'true' && steps.terraform-init-step.conclusion == 'success'
        run: |
          S3_BUCKET_NAME=$(terraform -chdir=infra output -raw s3_static_site_bucket_name)
          echo "s3_bucket_name_for_destroy=$S3_BUCKET_NAME" >> $GITHUB_OUTPUT # Usar um nome de output exclusivo

      # Empty S3 Bucket Before Destroy
      - name: Empty S3 Bucket Before Destroy
        id: empty-s3-bucket-before-destroy
        if: steps.read-destroy-config.outputs.destroy == 'true' && steps.get-s3-bucket-name-destroy.conclusion == 'success'
        run: |
          # use output 'get-s3-bucket-name-destroy'
          AWS_S3_BUCKET_NAME=${{ steps.get-s3-bucket-name-destroy.outputs.s3_bucket_name_for_destroy }}
          echo "Attempting to empty s3://${AWS_S3_BUCKET_NAME} before destroy..."

          # Check if the bucket name is set
          if [ -z "${AWS_S3_BUCKET_NAME}" ]; then
            echo "Error: S3 bucket name could not be determined. Aborting bucket empty process."
            exit 1
          fi

          # list and delete ALL object versions in the bucket
          aws s3api list-object-versions --bucket "${AWS_S3_BUCKET_NAME}" | \
          jq -r '.Versions[] | {Key: .Key, VersionId: .VersionId}' | \
          jq -s '{Objects: .}' | \
          aws s3api delete-objects --bucket "${AWS_S3_BUCKET_NAME}" --delete-mfa "" --cli-input-json file:///dev/stdin

          # List and delete all delete markers in the bucket
          aws s3api list-object-versions --bucket "${AWS_S3_BUCKET_NAME}" | \
          jq -r '.DeleteMarkers[] | {Key: .Key, VersionId: .VersionId}' | \
          jq -s '{Objects: .}' | \
          aws s3api delete-objects --bucket "${AWS_S3_BUCKET_NAME}" --delete-mfa "" --cli-input-json file:///dev/stdin

          echo "Bucket s3://${AWS_S3_BUCKET_NAME} should now be empty."

      - name: Terraform Destroy
        if: steps.read-destroy-config.outputs.destroy == 'true' && steps.empty-s3-bucket-before-destroy.conclusion == 'success'
        id: terraform-destroy
        run: |
          cd infra
          terraform workspace select ${{ inputs.environment }} || terraform workspace new ${{ inputs.environment }}
          terraform destroy \
            -var-file="./envs/${{ inputs.environment }}/terraform.tfvars" \
            -var="account_username=${{ github.actor }}" \
            -var="region=${{ inputs.aws-region }}" \
            -var="environment=${{ inputs.environment }}" \
            -auto-approve